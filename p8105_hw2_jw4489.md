p8105_hw2_jw4489
================
2023-10-04

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem 1

##### First, clean the data in pols-month.csv.

``` r
pols_month_df = 
  read_csv("p1data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.numeric(year),
    president = ifelse(
      prez_gop > prez_dem, "gop", "dem"
    )
  ) |> 
  select(-day, -prez_gop, -prez_dem)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
pols_month_df
```

    ## # A tibble: 822 × 9
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 January        23      51     253      23      45     198 dem      
    ##  2  1947 February       23      51     253      23      45     198 dem      
    ##  3  1947 March          23      51     253      23      45     198 dem      
    ##  4  1947 April          23      51     253      23      45     198 dem      
    ##  5  1947 May            23      51     253      23      45     198 dem      
    ##  6  1947 June           23      51     253      23      45     198 dem      
    ##  7  1947 July           23      51     253      23      45     198 dem      
    ##  8  1947 August         23      51     253      23      45     198 dem      
    ##  9  1947 September      23      51     253      23      45     198 dem      
    ## 10  1947 October        23      51     253      23      45     198 dem      
    ## # ℹ 812 more rows

##### Second, clean the data in snp.csv using a similar process to the above.

``` r
snp_df = 
  read_csv("p1data/snp.csv") |>
  janitor::clean_names() |> 
  mutate(
    date = format(as.Date(date, format = "%m/%d/%y"), "%Y/%m/%d")
  ) |> 
  separate(date, into = c("year", "month", "day"), sep = "/") |> 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.numeric(year)) |>
  arrange(year, month) |>
  relocate(year, month, everything())
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_df
```

    ## # A tibble: 787 × 4
    ##     year month    day   close
    ##    <dbl> <chr>    <chr> <dbl>
    ##  1  1969 April    01    104. 
    ##  2  1969 August   01     95.5
    ##  3  1969 December 01     92.1
    ##  4  1969 February 03     98.1
    ##  5  1969 January  02    103. 
    ##  6  1969 July     01     91.8
    ##  7  1969 June     02     97.7
    ##  8  1969 March    03    102. 
    ##  9  1969 May      01    103. 
    ## 10  1969 November 03     93.8
    ## # ℹ 777 more rows

##### Third, tidy the unemployment data.

``` r
unemployment_df = 
  read_csv("p1data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |>
  arrange(year, month)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unemployment_df
```

    ## # A tibble: 816 × 3
    ##     year month unemployment
    ##    <dbl> <chr>        <dbl>
    ##  1  1948 apr            3.9
    ##  2  1948 aug            3.9
    ##  3  1948 dec            4  
    ##  4  1948 feb            3.8
    ##  5  1948 jan            3.4
    ##  6  1948 jul            3.6
    ##  7  1948 jun            3.6
    ##  8  1948 mar            4  
    ##  9  1948 may            3.5
    ## 10  1948 nov            3.8
    ## # ℹ 806 more rows

##### Join the datasets.

``` r
merged_df = left_join(pols_month_df,snp_df, by = c("year", "month")) |> 
  left_join(unemployment_df, by = c("year", "month"))

merged_df
```

    ## # A tibble: 822 × 12
    ##     year month   gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president day  
    ##    <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <chr>
    ##  1  1947 January      23      51     253      23      45     198 dem       <NA> 
    ##  2  1947 Februa…      23      51     253      23      45     198 dem       <NA> 
    ##  3  1947 March        23      51     253      23      45     198 dem       <NA> 
    ##  4  1947 April        23      51     253      23      45     198 dem       <NA> 
    ##  5  1947 May          23      51     253      23      45     198 dem       <NA> 
    ##  6  1947 June         23      51     253      23      45     198 dem       <NA> 
    ##  7  1947 July         23      51     253      23      45     198 dem       <NA> 
    ##  8  1947 August       23      51     253      23      45     198 dem       <NA> 
    ##  9  1947 Septem…      23      51     253      23      45     198 dem       <NA> 
    ## 10  1947 October      23      51     253      23      45     198 dem       <NA> 
    ## # ℹ 812 more rows
    ## # ℹ 2 more variables: close <dbl>, unemployment <dbl>

##### Summarize the datasets.

The `pols-month` dataset contains 822 and 9 columns. It contains various
variables including `year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`,
`gov_dem`, `sen_dem`, `rep_dem`, `president`. The range is 1947 to 2015.

The `snp` dataset contains 787 rows and 4 columns. It contains `year`,
`month`, `close`. The range is 1969 to 2068.

The `unemployment` dataset contains 816 rows and 3 columns. It contains
`year`, `month`, `unemployment`. The range is 1948 to 2015.

The merged dataset `merged_df` contains 822 observations and 12. It
contains various variables including `year`, `month`, `gov_gop`,
`sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`.

## Problem 2

##### Read and clean the Mr. Trash Wheel sheet.

``` r
trash_wheel_df = 
  read_excel("p2data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel", 
             skip = 1) |> 
  janitor::clean_names() |>
  drop_na(dumpster) |> 
  select(dumpster:homes_powered)|> 
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    name = "Mr. Trash Wheel",
    year = as.numeric(year)
  )
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
trash_wheel_df
```

    ## # A tibble: 584 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, name <chr>

##### Import, clean, and organize the data for Professor Trash Wheel and Gwynnda.

``` r
prof_df = 
  read_excel("p2data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel", 
             skip = 1) |> 
  janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    name = "Professor Trash Wheel",
    year = as.numeric(year)
  )

prof_df
```

    ## # A tibble: 106 × 14
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 96 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, name <chr>

``` r
gwynnda_df = 
  read_excel("p2data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    name = "Gwynnda Trash Wheel",
    year = as.numeric(year)
  )

gwynnda_df
```

    ## # A tibble: 155 × 13
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 145 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, name <chr>

##### Combine the cleaned datasets with the Mr. Trash Wheel dataset to produce a single tidy dataset.

``` r
combined_df = bind_rows(trash_wheel_df, prof_df, gwynnda_df) |> 
  select(trash_wheel_name = "name",everything())

combined_df
```

    ## # A tibble: 845 × 15
    ##    trash_wheel_name dumpster month  year date                weight_tons
    ##    <chr>               <dbl> <chr> <dbl> <dttm>                    <dbl>
    ##  1 Mr. Trash Wheel         1 May    2014 2014-05-16 00:00:00        4.31
    ##  2 Mr. Trash Wheel         2 May    2014 2014-05-16 00:00:00        2.74
    ##  3 Mr. Trash Wheel         3 May    2014 2014-05-16 00:00:00        3.45
    ##  4 Mr. Trash Wheel         4 May    2014 2014-05-17 00:00:00        3.1 
    ##  5 Mr. Trash Wheel         5 May    2014 2014-05-17 00:00:00        4.06
    ##  6 Mr. Trash Wheel         6 May    2014 2014-05-20 00:00:00        2.71
    ##  7 Mr. Trash Wheel         7 May    2014 2014-05-21 00:00:00        1.91
    ##  8 Mr. Trash Wheel         8 May    2014 2014-05-28 00:00:00        3.7 
    ##  9 Mr. Trash Wheel         9 June   2014 2014-06-05 00:00:00        2.52
    ## 10 Mr. Trash Wheel        10 June   2014 2014-06-11 00:00:00        3.76
    ## # ℹ 835 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

##### Summarize the datasets.

The `Mr. trash wheel` dataset contains 584 rows and 15 columns.

The `Professor Trash Wheel` dataset contains 106 rows and 14 columns.
For available data, the total weight of trash collected by Professor
Trash Wheel is 216.26 tons.

The `Gwynnda Trash Wheel` dataset contains 155 rows and 13 columns. For
available data, the total number of cigarette butts collected by Gwynnda
in July of 2021 is 16300.

The combined dataset contains 845 rows and 15 columns.

The datasets contains various variables, inclusing “month”, “year”,
“date”, “weight_tons”, “volume_cubic_yards”, “plastic_bottles”, and
“polystyrene”. These variables represent the characteristics of trash
collected.

## Problem 3

##### Import, clean, and tidy the dataset of baseline demographics.

``` r
baseline_df = 
  read_csv("p3data/MCI_baseline.csv", 
           skip = 1) |> 
  janitor::clean_names() |>
  mutate(
    sex = replace(sex, sex == 1, "male"),
    sex = replace(sex, sex == 0, "female"),
    apoe4 = replace(apoe4, apoe4 == 1, "carrier"),
    apoe4 = replace(apoe4, apoe4 == 0, "non-carrier"),
    ) |>
  filter(age_at_onset > current_age)
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
baseline_df  
```

    ## # A tibble: 93 × 6
    ##       id current_age sex    education apoe4       age_at_onset
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>       <chr>       
    ##  1     3        62.5 male          16 carrier     66.8        
    ##  2     5        66   male          16 non-carrier 68.7        
    ##  3     7        66.5 male          18 non-carrier 74          
    ##  4    13        63.1 male          12 carrier     69          
    ##  5    14        58.4 female        20 non-carrier 66.2        
    ##  6    18        67.8 male          16 non-carrier 69.8        
    ##  7    22        67.3 female        20 carrier     74.6        
    ##  8    26        64.8 female        20 carrier     71.1        
    ##  9    30        66.3 female        12 non-carrier 73.1        
    ## 10    39        68.3 female        16 carrier     70.2        
    ## # ℹ 83 more rows

##### Discussion.

There are several important steps in the import process. First, data
import. The dataset is imported from a CSV file named “MCI_baseline.csv”
using the `read_csv` function. The `skip = 1` argument skips the first
row of the CSV file. Second, data cleaning. The `janitor::clean_names()`
function is used to clean the column names, ensuring they are in a
consistent format. Lastly, data transformation. The `mutate` function is
used to create or modify columns in the dataset. The “sex” column is
being replaced with “male” for values of 1 and “female” for values of 0,
and the “apoe4” column is being replaced with “carrier” for values of 1
and “non-carrier” for values of 0. The `filter` function is used to
remove any participants who do not meet the stated inclusion criteria.

The dataset contains variables including “id”, “current_age”, “sex”,
“education”, “apoe4”, and “age_at_onset”. It provides the
characteristics of the participants. The dataset contains 93 rows and 6
columns.

93 participants were recruited, and 93 participants develop MCI. The
average baseline age is 66. The proportion of women in the study are
APOE4 carriers is 67%.

##### Import, clean, and tidy the dataset of longitudinally observed biomarker values.

``` r
amyloid_df = 
  read_csv("p3data/mci_amyloid.csv", 
           skip = 1)|>
  janitor::clean_names() |>
  rename("id" = "study_id")
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
amyloid_df  
```

    ## # A tibble: 487 × 6
    ##       id baseline    time_2      time_4      time_6      time_8     
    ##    <dbl> <chr>       <chr>       <chr>       <chr>       <chr>      
    ##  1     1 0.1105487   <NA>        0.109325197 0.104756131 0.107257697
    ##  2     2 0.107481183 0.109157373 0.109457839 0.105729713 0.10661845 
    ##  3     3 0.106087034 0.108744509 0.106065035 <NA>        0.106152357
    ##  4     4 0.109251358 0.108699686 0.110540386 0.107476797 0.111212209
    ##  5     5 0.107950408 0.112273883 0.115139677 0.106606054 0.106052066
    ##  6     6 0.112426974 0.112853415 0.11143945  0.110279277 0.114982747
    ##  7     7 0.112246391 <NA>        0.104251905 0.112485583 0.112055612
    ##  8     8 0.109563372 0.109470828 <NA>        0.108742168 0.110268552
    ##  9     9 0.112101884 0.109781199 0.108832888 <NA>        <NA>       
    ## 10    10 0.1116094   0.111592149 <NA>        <NA>        0.110051296
    ## # ℹ 477 more rows

##### Discussion

Importing this dataset is similar to importing the `MCI_baseline`
dataset. Firstly, the dataset is imported from a CSV file named
“mci_amyloid.csv” using the `read_csv` function. The `skip = 1` argument
skips the first row of the CSV file. Secondly, the
`janitor::clean_names()` function is used to clean the column names,
ensuring they are in a consistent format. Lastly, to stay consistent
with `baseline_df`, I rename the variable “study_id” to “id”.

The dataset contains variables including “id”, “baseline”, “time_2”,
“time_4”, “time_6”, and “time_8”. It presents the longitudinally
observed biomarker values of participants. The dataset contains 487 rows
and 6 columns.

##### Check wheather some participants appear in only the baseline or amyloid datasets.

``` r
merged_df_p3 = 
  full_join(baseline_df, amyloid_df, by = c("id"))

merged_df_p3
```

    ## # A tibble: 490 × 11
    ##       id current_age sex    education apoe4  age_at_onset baseline time_2 time_4
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>  <chr>        <chr>    <chr>  <chr> 
    ##  1     3        62.5 male          16 carri… 66.8         0.10608… 0.108… 0.106…
    ##  2     5        66   male          16 non-c… 68.7         0.10795… 0.112… 0.115…
    ##  3     7        66.5 male          18 non-c… 74           0.11224… <NA>   0.104…
    ##  4    13        63.1 male          12 carri… 69           0.11030… 0.108… 0.108…
    ##  5    14        58.4 female        20 non-c… 66.2         <NA>     <NA>   <NA>  
    ##  6    18        67.8 male          16 non-c… 69.8         0.11413… 0.107… 0.110…
    ##  7    22        67.3 female        20 carri… 74.6         0.10932… <NA>   0.107…
    ##  8    26        64.8 female        20 carri… 71.1         0.10474… 0.110… 0.106…
    ##  9    30        66.3 female        12 non-c… 73.1         0.10931… 0.111… 0.107…
    ## 10    39        68.3 female        16 carri… 70.2         0.10442… <NA>   0.103…
    ## # ℹ 480 more rows
    ## # ℹ 2 more variables: time_6 <chr>, time_8 <chr>

There are some participants appear in only the baseline or amyloid
datasets. 397 participants are only in the amyloid dataset, and 3
participants are only in the baseline dataset. According to this, I find
that there are more participants appear in only the amyloid dataset than
the baseline dataset.

##### Merge the datasets so that only participants who appear in both datasets are retained.

``` r
both_df = 
  inner_join(baseline_df, amyloid_df,by = c("id"))

both_df
```

    ## # A tibble: 90 × 11
    ##       id current_age sex    education apoe4  age_at_onset baseline time_2 time_4
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>  <chr>        <chr>    <chr>  <chr> 
    ##  1     3        62.5 male          16 carri… 66.8         0.10608… 0.108… 0.106…
    ##  2     5        66   male          16 non-c… 68.7         0.10795… 0.112… 0.115…
    ##  3     7        66.5 male          18 non-c… 74           0.11224… <NA>   0.104…
    ##  4    13        63.1 male          12 carri… 69           0.11030… 0.108… 0.108…
    ##  5    18        67.8 male          16 non-c… 69.8         0.11413… 0.107… 0.110…
    ##  6    22        67.3 female        20 carri… 74.6         0.10932… <NA>   0.107…
    ##  7    26        64.8 female        20 carri… 71.1         0.10474… 0.110… 0.106…
    ##  8    30        66.3 female        12 non-c… 73.1         0.10931… 0.111… 0.107…
    ##  9    39        68.3 female        16 carri… 70.2         0.10442… <NA>   0.103…
    ## 10    43        67.1 female        16 carri… 71.6         0.11042… 0.105… <NA>  
    ## # ℹ 80 more rows
    ## # ℹ 2 more variables: time_6 <chr>, time_8 <chr>

``` r
summary(both_df)
```

    ##        id          current_age        sex              education    
    ##  Min.   :  3.00   Min.   :58.10   Length:90          Min.   :12.00  
    ##  1st Qu.: 93.25   1st Qu.:63.70   Class :character   1st Qu.:16.00  
    ##  Median :283.00   Median :65.95   Mode  :character   Median :16.00  
    ##  Mean   :245.77   Mean   :65.68                      Mean   :16.49  
    ##  3rd Qu.:365.75   3rd Qu.:67.67                      3rd Qu.:18.00  
    ##  Max.   :471.00   Max.   :71.60                      Max.   :20.00  
    ##     apoe4           age_at_onset         baseline            time_2         
    ##  Length:90          Length:90          Length:90          Length:90         
    ##  Class :character   Class :character   Class :character   Class :character  
    ##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##     time_4             time_6             time_8         
    ##  Length:90          Length:90          Length:90         
    ##  Class :character   Class :character   Class :character  
    ##  Mode  :character   Mode  :character   Mode  :character  
    ##                                                          
    ##                                                          
    ## 

The resulting dataset contains 90 rows and 11 columns. This means that
there are 90 participants appear in both datasets. Compared to the
dataset `merged_df_p3`, it has 24 less rows, which are the participants
who only appear in one of the datasets. In addition, the resulting
dataset contains variables including “id”, “current_age”, “sex”,
“education”, “apoe4”, “age_at_onset”, “baseline”, “time_2”, “time_4”,
“time_6”, and “time_8”.

##### Export the dataset.

``` r
write.csv(both_df, "p3data/merged_both_contained.csv", row.names = FALSE)
```
