---
title: "p8105_hw2_jw4489"
output: github_document
date: "2023-10-04"
---

```{r}
library(tidyverse)
library(readxl)
```


## Problem 1

##### First, clean the data in pols-month.csv.

```{r}
pols_month_df = 
  read_csv("p1data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.numeric(year),
    president = ifelse(
      prez_gop > prez_dem, "gop", "dem"
    )
  ) |> 
  select(-day, -prez_gop, -prez_dem)

pols_month_df
```

##### Second, clean the data in snp.csv using a similar process to the above.

```{r}
snp_df = 
  read_csv("p1data/snp.csv") |>
  janitor::clean_names() |> 
  mutate(
    date = format(as.Date(date, format = "%m/%d/%y"), "%Y/%m/%d")
  ) |> 
  separate(date, into = c("year", "month", "day"), sep = "/") |> 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.numeric(year)) |>
  arrange(year, month) |>
  relocate(year, month, everything())

snp_df
```

##### Third, tidy the unemployment data.

```{r}
unemployment_df = 
  read_csv("p1data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |>
  arrange(year, month)

unemployment_df
```

##### Join the datasets.

```{r}
merged_df = left_join(pols_month_df,snp_df, by = c("year", "month")) |> 
  left_join(unemployment_df, by = c("year", "month"))

merged_df
```

##### Summarize the datasets.

The `pols-month` dataset contains `r nrow(pols_month_df)` and `r ncol(pols_month_df)` columns. It contains various variables including `year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`, `president`. The range is `r pull(pols_month_df, year) |> min()` to `r pull(pols_month_df, year) |> max()`. 

The `snp` dataset contains `r nrow(snp_df)` rows and `r ncol(snp_df)` columns. It contains `year`, `month`, `close`. The range is `r pull(snp_df, year) |> min()` to `r pull(snp_df, year) |> max()`.

The `unemployment` dataset contains `r nrow(unemployment_df)` rows and `r ncol(unemployment_df)` columns. It contains `year`, `month`, `unemployment`. The range is `r pull(unemployment_df, year) |> min()` to `r pull(unemployment_df, year) |> max()`.

The merged dataset `merged_df` contains `r nrow(merged_df)` observations and `r ncol(merged_df)`. It contains various variables including `year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`. 

## Problem 2

##### Read and clean the Mr. Trash Wheel sheet.

```{r}
trash_wheel_df = 
  read_excel("p2data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel", 
             skip = 1) |> 
  janitor::clean_names() |>
  drop_na(dumpster) |> 
  select(dumpster:homes_powered)|> 
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    name = "Mr. Trash Wheel",
    year = as.numeric(year)
  )

trash_wheel_df
```

##### Import, clean, and organize the data for Professor Trash Wheel and Gwynnda.

```{r}
prof_df = 
  read_excel("p2data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel", 
             skip = 1) |> 
  janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    name = "Professor Trash Wheel",
    year = as.numeric(year)
  )

prof_df
```

```{r}
gwynnda_df = 
  read_excel("p2data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    name = "Gwynnda Trash Wheel",
    year = as.numeric(year)
  )

gwynnda_df
```

##### Combine the cleaned datasets with the Mr. Trash Wheel dataset to produce a single tidy dataset. 

```{r}
combined_df = bind_rows(trash_wheel_df, prof_df, gwynnda_df) |> 
  select(trash_wheel_name = "name",everything())

combined_df
```

##### Summarize the datasets.

The `Mr. trash wheel` dataset contains `r nrow(trash_wheel_df)` rows and `r ncol(trash_wheel_df)` columns.

The `Professor Trash Wheel` dataset contains `r nrow(prof_df)` rows and `r ncol(prof_df)` columns. For available data, the total weight of trash collected by Professor Trash Wheel is `r sum(prof_df|>pull(weight_tons))` tons.

The `Gwynnda Trash Wheel` dataset contains `r nrow(gwynnda_df)` rows and `r ncol(gwynnda_df)` columns. For available data, the total number of cigarette butts collected by Gwynnda in July of 2021 is `r subset(gwynnda_df, year == 2021 & month == "July") |> pull(cigarette_butts) |> sum()|>as.integer()`.

The combined dataset contains `r nrow(combined_df)` rows and `r ncol(combined_df)` columns. 

The datasets contains various variables, inclusing “month”, “year”, “date”, “weight_tons”, “volume_cubic_yards”, “plastic_bottles”, and “polystyrene”. These variables represent the characteristics of trash collected.

## Problem 3

##### Import, clean, and tidy the dataset of baseline demographics.

```{r}
baseline_df = 
  read_csv("p3data/MCI_baseline.csv", 
           skip = 1) |> 
  janitor::clean_names() |>
  mutate(
    sex = replace(sex, sex == 1, "male"),
    sex = replace(sex, sex == 0, "female"),
    apoe4 = replace(apoe4, apoe4 == 1, "carrier"),
    apoe4 = replace(apoe4, apoe4 == 0, "non-carrier"),
    ) |>
  filter(age_at_onset == "." | age_at_onset > current_age)

baseline_df  
```

##### Discussion.

There are several important steps in the import process. First, data import. The dataset is imported from a CSV file named "MCI_baseline.csv" using the `read_csv` function. The `skip = 1` argument skips the first row of the CSV file. Second, data cleaning. The `janitor::clean_names()` function is used to clean the column names, ensuring they are in a consistent format. Lastly, data transformation. The `mutate` function is used to create or modify columns in the dataset. The "sex" column is being replaced with "male" for values of 1 and "female" for values of 0, and the "apoe4" column is being replaced with "carrier" for values of 1 and "non-carrier" for values of 0. The `filter` function is used to remove any participants who do not meet the stated inclusion criteria.

The dataset contains variables including "id", "current_age", "sex", "education", "apoe4", and "age_at_onset". It provides the characteristics of the participants. The dataset contains `r nrow(baseline_df)` rows and `r ncol(baseline_df)` columns.

`r nrow(baseline_df)` participants were recruited, and `r filter(baseline_df, age_at_onset != ".") |> nrow()` participants develop MCI. The average baseline age is `r mean(pull(baseline_df, current_age)) |> round(digits = 0)`. The proportion of women in the study are APOE4 carriers is `r scales::percent(nrow(filter(baseline_df, sex == "female" & apoe4 =="carrier")) / nrow(filter(baseline_df, sex == "female")))`.

##### Import, clean, and tidy the dataset of longitudinally observed biomarker values.

```{r}
amyloid_df = 
  read_csv("p3data/mci_amyloid.csv", 
           skip = 1)|>
  janitor::clean_names() |>
  rename("id" = "study_id")

amyloid_df  
```

##### Discussion

Importing this dataset is similar to importing the `MCI_baseline` dataset. Firstly, the dataset is imported from a CSV file named "mci_amyloid.csv" using the  `read_csv` function. The `skip = 1` argument skips the first row of the CSV file. Secondly, the `janitor::clean_names()` function is used to clean the column names, ensuring they are in a consistent format. Lastly, to stay consistent with `baseline_df`, I rename the variable "study_id" to "id". 

The dataset contains variables including "id", "baseline", "time_2", "time_4", "time_6", and "time_8". It presents the longitudinally observed biomarker values of participants. The dataset contains `r nrow(amyloid_df)` rows and `r ncol(amyloid_df)` columns.

##### Check wheather some participants appear in only the baseline or amyloid datasets.

```{r}
merged_df_p3 = 
  full_join(baseline_df, amyloid_df, by = c("id"))

merged_df_p3
```

There are some participants appear in only the baseline or amyloid datasets. `r nrow(merged_df_p3) - nrow(baseline_df)` participants are only in the amyloid dataset, and `r nrow(merged_df_p3) - nrow(amyloid_df)` participants are only in the baseline dataset. According to this, I find that there are more participants appear in only the amyloid dataset than the baseline dataset.

##### Merge the datasets so that only participants who appear in both datasets are retained.

```{r}
both_df = 
  inner_join(baseline_df, amyloid_df,by = c("id"))

both_df
```

The resulting dataset contains `r nrow(both_df)` rows and `r ncol(both_df)` columns.
